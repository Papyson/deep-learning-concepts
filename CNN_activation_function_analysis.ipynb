{"cells":[{"cell_type":"markdown","metadata":{"id":"vGL0oNf2EAFS"},"source":["#MNIST DATASET"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3188438,"status":"ok","timestamp":1699640678697,"user":{"displayName":"ayobami oyewole","userId":"04197947382672123640"},"user_tz":-60},"id":"LIlf65pGByVD","outputId":"ed70d761-312c-4136-d05f-984e8a21c610"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1875/1875 [==============================] - 72s 38ms/step - loss: 0.6604 - accuracy: 0.7821 - val_loss: 0.1477 - val_accuracy: 0.9594\n","Epoch 2/10\n","1875/1875 [==============================] - 64s 34ms/step - loss: 0.1019 - accuracy: 0.9700 - val_loss: 0.0736 - val_accuracy: 0.9786\n","Epoch 3/10\n","1875/1875 [==============================] - 60s 32ms/step - loss: 0.0674 - accuracy: 0.9797 - val_loss: 0.0526 - val_accuracy: 0.9834\n","Epoch 4/10\n","1875/1875 [==============================] - 59s 31ms/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.0428 - val_accuracy: 0.9877\n","Epoch 5/10\n","1875/1875 [==============================] - 60s 32ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 0.0409 - val_accuracy: 0.9873\n","Epoch 6/10\n","1875/1875 [==============================] - 63s 33ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0348 - val_accuracy: 0.9888\n","Epoch 7/10\n","1875/1875 [==============================] - 61s 33ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0405 - val_accuracy: 0.9871\n","Epoch 8/10\n","1875/1875 [==============================] - 64s 34ms/step - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.0352 - val_accuracy: 0.9888\n","Epoch 9/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0307 - val_accuracy: 0.9895\n","Epoch 10/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0340 - val_accuracy: 0.9898\n","Epoch 1/10\n","1875/1875 [==============================] - 59s 31ms/step - loss: 0.1361 - accuracy: 0.9606 - val_loss: 0.0476 - val_accuracy: 0.9853\n","Epoch 2/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0520 - accuracy: 0.9841 - val_loss: 0.0394 - val_accuracy: 0.9871\n","Epoch 3/10\n","1875/1875 [==============================] - 59s 31ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0347 - val_accuracy: 0.9884\n","Epoch 4/10\n","1875/1875 [==============================] - 59s 32ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.0336 - val_accuracy: 0.9898\n","Epoch 5/10\n","1875/1875 [==============================] - 60s 32ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0360 - val_accuracy: 0.9885\n","Epoch 6/10\n","1875/1875 [==============================] - 61s 33ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0340 - val_accuracy: 0.9896\n","Epoch 7/10\n","1875/1875 [==============================] - 58s 31ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0440 - val_accuracy: 0.9878\n","Epoch 8/10\n","1875/1875 [==============================] - 59s 32ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.0338 - val_accuracy: 0.9901\n","Epoch 9/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0451 - val_accuracy: 0.9861\n","Epoch 10/10\n","1875/1875 [==============================] - 61s 33ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0420 - val_accuracy: 0.9887\n","Epoch 1/10\n","1875/1875 [==============================] - 57s 30ms/step - loss: 0.1440 - accuracy: 0.9558 - val_loss: 0.0483 - val_accuracy: 0.9864\n","Epoch 2/10\n","1875/1875 [==============================] - 55s 29ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.0407 - val_accuracy: 0.9870\n","Epoch 3/10\n","1875/1875 [==============================] - 57s 30ms/step - loss: 0.0326 - accuracy: 0.9897 - val_loss: 0.0301 - val_accuracy: 0.9907\n","Epoch 4/10\n","1875/1875 [==============================] - 54s 29ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0330 - val_accuracy: 0.9892\n","Epoch 5/10\n","1875/1875 [==============================] - 54s 29ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0326 - val_accuracy: 0.9910\n","Epoch 6/10\n","1875/1875 [==============================] - 58s 31ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0295 - val_accuracy: 0.9912\n","Epoch 7/10\n","1875/1875 [==============================] - 54s 29ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0438 - val_accuracy: 0.9885\n","Epoch 8/10\n","1875/1875 [==============================] - 55s 29ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0370 - val_accuracy: 0.9908\n","Epoch 9/10\n","1875/1875 [==============================] - 54s 29ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0393 - val_accuracy: 0.9903\n","Epoch 10/10\n","1875/1875 [==============================] - 56s 30ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0441 - val_accuracy: 0.9905\n","Epoch 1/10\n","1875/1875 [==============================] - 64s 33ms/step - loss: 0.1298 - accuracy: 0.9606 - val_loss: 0.0781 - val_accuracy: 0.9762\n","Epoch 2/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.0345 - val_accuracy: 0.9894\n","Epoch 3/10\n","1875/1875 [==============================] - 66s 35ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0417 - val_accuracy: 0.9876\n","Epoch 4/10\n","1875/1875 [==============================] - 63s 33ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0432 - val_accuracy: 0.9880\n","Epoch 5/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.0342 - val_accuracy: 0.9912\n","Epoch 6/10\n","1875/1875 [==============================] - 60s 32ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0345 - val_accuracy: 0.9903\n","Epoch 7/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0478 - val_accuracy: 0.9874\n","Epoch 8/10\n","1875/1875 [==============================] - 63s 34ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0425 - val_accuracy: 0.9907\n","Epoch 9/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0430 - val_accuracy: 0.9896\n","Epoch 10/10\n","1875/1875 [==============================] - 64s 34ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0519 - val_accuracy: 0.9881\n","Epoch 1/10\n","1875/1875 [==============================] - 61s 32ms/step - loss: 0.1381 - accuracy: 0.9573 - val_loss: 0.0613 - val_accuracy: 0.9799\n","Epoch 2/10\n","1875/1875 [==============================] - 59s 32ms/step - loss: 0.0597 - accuracy: 0.9821 - val_loss: 0.0550 - val_accuracy: 0.9836\n","Epoch 3/10\n","1875/1875 [==============================] - 63s 33ms/step - loss: 0.0500 - accuracy: 0.9851 - val_loss: 0.0458 - val_accuracy: 0.9862\n","Epoch 4/10\n","1875/1875 [==============================] - 63s 34ms/step - loss: 0.0391 - accuracy: 0.9883 - val_loss: 0.0393 - val_accuracy: 0.9879\n","Epoch 5/10\n","1875/1875 [==============================] - 62s 33ms/step - loss: 0.0316 - accuracy: 0.9905 - val_loss: 0.0680 - val_accuracy: 0.9822\n","Epoch 6/10\n","1875/1875 [==============================] - 59s 31ms/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.0570 - val_accuracy: 0.9857\n","Epoch 7/10\n","1875/1875 [==============================] - 61s 32ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0499 - val_accuracy: 0.9859\n","Epoch 8/10\n","1875/1875 [==============================] - 66s 35ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0684 - val_accuracy: 0.9865\n","Epoch 9/10\n","1875/1875 [==============================] - 61s 32ms/step - loss: 0.0225 - accuracy: 0.9937 - val_loss: 0.0566 - val_accuracy: 0.9877\n","Epoch 10/10\n","1875/1875 [==============================] - 61s 32ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.0637 - val_accuracy: 0.9881\n","313/313 - 4s - loss: 0.0340 - accuracy: 0.9898 - 4s/epoch - 11ms/step\n","sigmoid Test Accuracy: 0.989799976348877\n","313/313 - 2s - loss: 0.0420 - accuracy: 0.9887 - 2s/epoch - 8ms/step\n","tanh Test Accuracy: 0.9886999726295471\n","313/313 - 2s - loss: 0.0441 - accuracy: 0.9905 - 2s/epoch - 8ms/step\n","relu Test Accuracy: 0.9904999732971191\n","313/313 - 3s - loss: 0.0519 - accuracy: 0.9881 - 3s/epoch - 8ms/step\n","elu Test Accuracy: 0.988099992275238\n","313/313 - 3s - loss: 0.0637 - accuracy: 0.9881 - 3s/epoch - 9ms/step\n","selu Test Accuracy: 0.988099992275238\n"]}],"source":["# Import Necessary Libraries\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","# Load and Preprocess Datasets\n","(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = datasets.mnist.load_data()\n","(train_images_cifar, train_labels_cifar), (test_images_cifar, test_labels_cifar) = datasets.cifar10.load_data()\n","\n","train_images_mnist, test_images_mnist = train_images_mnist / 255.0, test_images_mnist / 255.0\n","train_images_cifar, test_images_cifar = train_images_cifar / 255.0, test_images_cifar / 255.0\n","\n","# Build CNN Architecture\n","def create_model(activation_func):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation=activation_func, input_shape=(28, 28, 1)))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation=activation_func))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation=activation_func))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation=activation_func))\n","    model.add(layers.Dense(10, activation='softmax'))  # 10 classes for MNIST\n","\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","# Implement Activation Functions\n","activation_functions = ['sigmoid', 'tanh', 'relu', 'elu', 'selu']\n","models_dict = {}\n","\n","for activation_func in activation_functions:\n","    model = create_model(activation_func)\n","    models_dict[activation_func] = model\n","\n","# Compile and Train the Model\n","def train_model(model, train_images, train_labels, test_images, test_labels, epochs=5):\n","    history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n","    return history\n","\n","# Train and Record Metrics\n","history_dict = {}\n","\n","for activation_func, model in models_dict.items():\n","    history = train_model(model, train_images_mnist, train_labels_mnist, test_images_mnist, test_labels_mnist)\n","    history_dict[activation_func] = history\n","\n","# Plot Training Metrics\n","def plot_metrics(history, activation_func):\n","    plt.figure(figsize=(12, 4))\n","\n","    # Plot Loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title(f'{activation_func} - Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Plot Accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title(f'{activation_func} - Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# Evaluate Model Performance\n","for activation_func, model in models_dict.items():\n","    test_loss, test_acc = model.evaluate(test_images_mnist, test_labels_mnist, verbose=2)\n","    print(f'{activation_func} Test Accuracy: {test_acc}')"]},{"cell_type":"markdown","metadata":{"id":"s6IoxFAASGrn"},"source":["Choose the activation function that provides the best performance.\n","Sigmoid: loss: 0.0345 - accuracy: 0.9889\n","Relu: loss: 0.0369 - accuracy: 0.9908. For the MNIST Dataset after 10 epochs Relu seems to have the highest accuracy but Sigmoid has a lower loss."]},{"cell_type":"markdown","metadata":{"id":"4qRjqTtnD-k8"},"source":["#CIFAR-10 DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"k61E2CwCEH4A"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1563/1563 [==============================] - 76s 48ms/step - loss: 2.1518 - accuracy: 0.1819 - val_loss: 1.9177 - val_accuracy: 0.3025\n","Epoch 2/5\n","1563/1563 [==============================] - 73s 47ms/step - loss: 1.7825 - accuracy: 0.3502 - val_loss: 1.6606 - val_accuracy: 0.4072\n","Epoch 3/5\n","1563/1563 [==============================] - 70s 45ms/step - loss: 1.5997 - accuracy: 0.4290 - val_loss: 1.5261 - val_accuracy: 0.4487\n","Epoch 4/5\n","1563/1563 [==============================] - 72s 46ms/step - loss: 1.4913 - accuracy: 0.4688 - val_loss: 1.4475 - val_accuracy: 0.4893\n","Epoch 5/5\n","1563/1563 [==============================] - 69s 44ms/step - loss: 1.4204 - accuracy: 0.4934 - val_loss: 1.3925 - val_accuracy: 0.4990\n","Epoch 1/5\n","1563/1563 [==============================] - 76s 48ms/step - loss: 1.4060 - accuracy: 0.5012 - val_loss: 1.1861 - val_accuracy: 0.5865\n","Epoch 2/5\n","1563/1563 [==============================] - 73s 47ms/step - loss: 1.1253 - accuracy: 0.6052 - val_loss: 1.1448 - val_accuracy: 0.6001\n","Epoch 3/5\n","1563/1563 [==============================] - 69s 44ms/step - loss: 1.0244 - accuracy: 0.6408 - val_loss: 1.0288 - val_accuracy: 0.6415\n","Epoch 4/5\n","1563/1563 [==============================] - 70s 45ms/step - loss: 0.9520 - accuracy: 0.6720 - val_loss: 1.0280 - val_accuracy: 0.6463\n","Epoch 5/5\n","1563/1563 [==============================] - 72s 46ms/step - loss: 0.8983 - accuracy: 0.6888 - val_loss: 1.0033 - val_accuracy: 0.6540\n","Epoch 1/5\n","1563/1563 [==============================] - 70s 44ms/step - loss: 1.5182 - accuracy: 0.4434 - val_loss: 1.2430 - val_accuracy: 0.5548\n","Epoch 2/5\n","1563/1563 [==============================] - 67s 43ms/step - loss: 1.1475 - accuracy: 0.5933 - val_loss: 1.0692 - val_accuracy: 0.6195\n","Epoch 3/5\n","1563/1563 [==============================] - 67s 43ms/step - loss: 1.0029 - accuracy: 0.6454 - val_loss: 1.0025 - val_accuracy: 0.6482\n","Epoch 4/5\n","1563/1563 [==============================] - 68s 44ms/step - loss: 0.9079 - accuracy: 0.6810 - val_loss: 0.9077 - val_accuracy: 0.6811\n","Epoch 5/5\n","1563/1563 [==============================] - 69s 44ms/step - loss: 0.8320 - accuracy: 0.7063 - val_loss: 0.8681 - val_accuracy: 0.6964\n","Epoch 1/5\n","1563/1563 [==============================] - 77s 49ms/step - loss: 1.3857 - accuracy: 0.5069 - val_loss: 1.1875 - val_accuracy: 0.5828\n","Epoch 2/5\n","1563/1563 [==============================] - 76s 49ms/step - loss: 1.0749 - accuracy: 0.6209 - val_loss: 0.9990 - val_accuracy: 0.6480\n","Epoch 3/5\n","1563/1563 [==============================] - 74s 47ms/step - loss: 0.9400 - accuracy: 0.6718 - val_loss: 1.0083 - val_accuracy: 0.6505\n","Epoch 4/5\n","1563/1563 [==============================] - 78s 50ms/step - loss: 0.8476 - accuracy: 0.7025 - val_loss: 0.9306 - val_accuracy: 0.6808\n","Epoch 5/5\n","1563/1563 [==============================] - 73s 47ms/step - loss: 0.7689 - accuracy: 0.7308 - val_loss: 0.9416 - val_accuracy: 0.6796\n","Epoch 1/5\n","1563/1563 [==============================] - 77s 49ms/step - loss: 1.4451 - accuracy: 0.4895 - val_loss: 1.2981 - val_accuracy: 0.5471\n","Epoch 2/5\n","1563/1563 [==============================] - 75s 48ms/step - loss: 1.1622 - accuracy: 0.5929 - val_loss: 1.1008 - val_accuracy: 0.6181\n","Epoch 3/5\n","1563/1563 [==============================] - 75s 48ms/step - loss: 1.0362 - accuracy: 0.6376 - val_loss: 1.0511 - val_accuracy: 0.6308\n","Epoch 4/5\n","1563/1563 [==============================] - 76s 49ms/step - loss: 0.9388 - accuracy: 0.6727 - val_loss: 0.9724 - val_accuracy: 0.6644\n","Epoch 5/5\n","1563/1563 [==============================] - 72s 46ms/step - loss: 0.8677 - accuracy: 0.6976 - val_loss: 1.0966 - val_accuracy: 0.6384\n","313/313 - 3s - loss: 1.3925 - accuracy: 0.4990 - 3s/epoch - 11ms/step\n","sigmoid Test Accuracy (CIFAR10): 0.49900001287460327\n","313/313 - 4s - loss: 1.0033 - accuracy: 0.6540 - 4s/epoch - 12ms/step\n","tanh Test Accuracy (CIFAR10): 0.6539999842643738\n","313/313 - 3s - loss: 0.8681 - accuracy: 0.6964 - 3s/epoch - 10ms/step\n","relu Test Accuracy (CIFAR10): 0.696399986743927\n","313/313 - 4s - loss: 0.9416 - accuracy: 0.6796 - 4s/epoch - 14ms/step\n","elu Test Accuracy (CIFAR10): 0.6796000003814697\n","313/313 - 3s - loss: 1.0966 - accuracy: 0.6384 - 3s/epoch - 11ms/step\n","selu Test Accuracy (CIFAR10): 0.6384000182151794\n"]}],"source":["# Import Necessary Libraries\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","# Load and Preprocess CIFAR10 Dataset\n","(train_images_cifar, train_labels_cifar), (test_images_cifar, test_labels_cifar) = datasets.cifar10.load_data()\n","train_images_cifar, test_images_cifar = train_images_cifar / 255.0, test_images_cifar / 255.0\n","\n","# Build CNN Architecture for CIFAR10\n","def create_cifar_model(activation_func):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation=activation_func, input_shape=(32, 32, 3)))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation=activation_func))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation=activation_func))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation=activation_func))\n","    model.add(layers.Dense(10, activation='softmax'))  # 10 classes for CIFAR10\n","\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model\n","\n","# Implement Activation Functions for CIFAR10\n","activation_functions = ['sigmoid', 'tanh', 'relu', 'elu', 'selu']\n","cifar_models_dict = {}\n","\n","for activation_func in activation_functions:\n","    cifar_model = create_cifar_model(activation_func)\n","    cifar_models_dict[activation_func] = cifar_model\n","\n","# Compile and Train CIFAR10 Models\n","def train_cifar_model(model, train_images, train_labels, test_images, test_labels, epochs=5):\n","    history = model.fit(train_images, train_labels, epochs=epochs, validation_data=(test_images, test_labels))\n","    return history\n","\n","# Train and Record CIFAR10 Metrics\n","cifar_history_dict = {}\n","\n","for activation_func, cifar_model in cifar_models_dict.items():\n","    cifar_history = train_cifar_model(cifar_model, train_images_cifar, train_labels_cifar, test_images_cifar, test_labels_cifar)\n","    cifar_history_dict[activation_func] = cifar_history\n","\n","# Plot CIFAR10 Training Metrics\n","def plot_cifar_metrics(history, activation_func):\n","    plt.figure(figsize=(12, 4))\n","\n","    # Plot Loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title(f'{activation_func} - CIFAR10 Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Plot Accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title(f'{activation_func} - CIFAR10 Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# Evaluate CIFAR10 Model Performance\n","for activation_func, cifar_model in cifar_models_dict.items():\n","    test_loss, test_acc = cifar_model.evaluate(test_images_cifar, test_labels_cifar, verbose=2)\n","    print(f'{activation_func} Test Accuracy (CIFAR10): {test_acc}')\n"]},{"cell_type":"markdown","metadata":{"id":"YPdKOE_cSkGI"},"source":["Choose the activation function that provides the best performance for CIFAR10."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNXMQtAqY4rj7WwvLXAKdsJ","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}